To make a star have volume when you get close, you must include its data point twice in the speck file.
Without doing this, when the camera gets close, the point dissappears and only the halo is left over.
In addition, the color map color has to be be sufficiently bright (white) and have a large enough alpha.

To have the halo shape instead of texture, make sure datavar for texture is "linked" to the file to overlay

Finding how partiView handles angles was quite complicated. First, the documentation was very brief about it, and only described it
as Rx Ry Rz. The 0 0 0 config of the camera corresponds to facing parallel to the z axis, facnig the origin, with the x axis
extending out to the right and y axis up. 
Testing simple cases, I found that for single rotations about a coordinate axis, it made sense, but not when I composed rotations.
Initially, I thought the system was to first rotate in the x-y plane and then up toward the z axis, similar to latitute longitude, but 
that didn't work in many cases. 

I went to the source code at https://git.ncsa.illinois.edu/slevy/partiview to see if I could find something there. Although partiView itself is 
lightWeight, the source code is still too dense to just "read through". Certain partiView commands like "jump" take in rotation values, so 
I tried to see how it was converted, but there was little code documentation, and I quickly got to hardcoded matrix formulas with no descriptive
names. The file geometry.c seemed to contain most of the utility methods for these operations. However, I did find a comment nearby that described it as "azimuth, elevation, roll", and also YXZ. All along, I suspected that they were using some standard rotation system like Euler Angles, since all other systems require more information (still 3 degrees of freedom, but "spread out", like axis-angle form). 

I found a rotation converter https://www.andre-gaschler.com/rotationconverter/ that I used to convet axis-angle to Euler Angles. Axis-angle
is probably the easiest input data to create, since ultimately I would like to just specify the camera to look in a certain direction.
I use the cross product between that vector and the default camera (0, 0, -1) to find a mutually orthogonal rotation axis, and the dot product
to find the angle swept. 

I also learned that Euler Angles come in many conventions, and 3D rotation in general has many conventions, such as if we use axes fixed in the
body or the frame, or active and passive rotations, etc. However, this converter I found had convention choices permuting XYZ (as opposed to XZX
which is another common convention), so I chose the YXZ that I saw earlier. To test this, I decided to "request" that the camera look along 
<1, 0.5, -1>, and I calculated the axis-angle rotation by hand. I plugged into the converter and got the YXZ Euler Angles, and put them in 
partiView. Luckily, there is a builtin command called "where", which prints out a lot of useful positional information including the camera's 
"looking vector", and it matched my requested <1, 0.5, -1>, up to a very small numerical error. I tested this a couple more times with other
vectors, and it worked correctly as well. 

I also tested orienting myself in partiView randomly, and looking at the camera's direction vector. I again plugged that into axis-angle and then
the converter, and found the calculated Euler Angles. The first 2 matched exactly with what partiView said, but the 3rd angle was about 15% off.
I have no idea why, and I am fairly sure it was not a calculation mistake on my part. 

Now I was pretty confident that the converter was correct, and so I looked at its source code (which was nicely provided in github). Unfortunately,
it was very long and hard to read, and like partiView, the matrix math was all "baked in" and hard to reproduce. 

At this point, I figured out that I would need to convert axis-angle (or some form produceable from axis-angle) to Euler, but most guides
used the standard XYZ (roll pitch yaw) convention. Essentially the ordering of the axes determines the order of the multiplication of the 
elementary rotation matricies. This was a good guide: http://danceswithcode.net/engineeringnotes/rotations_in_3d/rotations_in_3d_part1.html  though
I refered to many other sources. These sources mainly used the composed rotation matrix form, so that's what I used.

The composed rotation matrix I need is created from Ry(v)Rx(u)Rz(w), which of course matches the YXZ form. These matricies are the standard 3D rotations matricies. I used Mathematica to multiply them. To solve for each angle, one can divide carefully chosen elements of the composed matrix
to isolate sin or cos of u, v, w. Just to make sure all my implicit conventions were correct, I testing this against the converter and it all
worked out.   

Finally, to get the rotation matrix from axis-angle I found a formula on wikipedia https://en.wikipedia.org/wiki/Rotation_matrix#In_three_dimensions and used that. There are no annoying conventions here, so it's a
simple plug in. 

I also investigated an alternative method of creating the rotation matrix, using a regular aziumth-elevation type rotation composition. Axis-angle
works well, but it causes some rolling (as in pitch, yaw, roll), and I wanted to see if I could avoid that. Azimuth-elevation is very much like
spherical polar coordinates, and a horizontal section rotated using this method would remain horizontal. I tried this, and it definately produced
different results, but there were some "fun" barrel rolls for some reason, and it was a little disorienting. I decided to stick with axis-angle. 

*Note this is a summary of my path to get the whole thing to work. There were several more dead ends than I mentioned and I also spent some time 
reminding myself how 3D rotations worked in general.


For the camera angles, I have 2 options, looking directly at the line of travel (similar to a rollar coaster), and fixating on a point. Switching between these options produces a smooth pan.

In order to record a video, partiview will save screenshots after each frame in a path. Specifically, load in a flight path manually, then command 'read makeFrames.cf" this instructs partiview to move to frame 1, save a snapshot,
move to frame 2, save, and so on. One can detach the viewing window using "detach" and also resize it using "winsize x y". This enables partiview to take screenshots at any resolution. Unfortunately it saves it directly into the main
directory, not a new folder, but this isn't a huge deal. I then wrote a small python script using opncv to stitch the frames together at 60 fps. 


In order to animate time-varying data, there are several options. One can specify velocity components for each star in the speck file, as a dataavar, and partiview will do a simple 
linear extrapolation in time. This is only good for linear motion. Another option is using the 'datatime' keyword in the speck file. For every star you want to move, you can provide
xyz coordinates for every step in time. There is no interpolation between these points, and so there has to be quite a few datatimes (several hundereds at least) to see smooth
motion. With this method, any sort of path can be produced (for any number of stars concurrently). There is a final method I found with minimal documentation. One can combine the two
previous methods, with linear interpolation between datatimes. However, unless there are many datatimes, this will produce choppy motion, and the velocities have to be updated
appropriately for each data time to make sure the extrapolation hits the next coordinate point. This is cumbersome and one might as well use the "pure datatimes" method. 


In addition to evolving position with time, one can also evolve other qualities with time, as long as they appear in the .SPECK file. This works best with continuous
variables, such as luminosty. All you need to do is to have it print out a non-constant value through time, and partiview will update the quality accordingly.



The only texture I was able to use was the one in the Digital Universe halo.pbm. I tried opening this file and modifying it using GIMP, but after I saved it, partiview had 
trouble recognizing it. It displayed a large square instead of the texture, which is what it does when there are no textures at all. Looking at the raw data using
a text editor, the data format was clearly different after I saved it using GIMP, so that might be the problem.

To fix this, one should use the .sgi format for images, which partiview also supports. When exporting this format from gimp, one can either select the "RLE compression" or
"No compression option". There are several difficulties however within partiview. For one thing, textures are general shown always facing the camera head on. For star halos, this
makes sense because we would not want to see a "flat" star, and the spherically symmetric enough. For showing detail on a planet however, it becomes impossible to oribt the planet,
as the same thing is always shown! There is a way to specify the actual orientation of a texture using the polyorivar command, which accepts 2 orthonormal vectors that define the 
plane of the texture. This is good to show disc galaxies, for example, but again for a planet it will appear flat when viewed edge-on. 

Another difficulity arises when looking at the texture straight on, and that is that it can appear partially transparent. Again, when showing pictures of galaxies with stars "underneath it",
it makes sense to have it be partially transparent. However, planets are not transparent, and it makes for quite an experience when one can see stars through the planet. Changing the 
alpha value on the texture had some effect, though it never made it fully opaque. I experimented with the planet's point color's opaqueness, but that didn't work. One can stack several points
on top of each other, with identical textures, and while that does improve the opaqueness, it never removes it, and the final image appears over-exposed and blurry.

When declaring textures in the .cf file, there are flags to indicate the mode of drawing textures. For example, the standard star halo uses the -M flag, modulate, which treats the texture
as a brightness channel, and respects the point's original color map color. There is another option, -O, over compost, which will obscure features behind it according to the alpha at each
point on the texture. This does succeed in making the planet opaque, but now there are other problems. 

It seems that when partiview says "obscure other features", they really meant that, regardless of depth. When I made a simple earth-sun system, and the sun was physically between the earth 
and the camera, it was actually entirely blocked by the earth texture. In other words, the texture is always the last thing drawn, regardless of depth. Some of the other command flags for 
adding textures did not have this problem, but of course, they made earth transparent. 

Another problem with the -O option, was that it had black "leftovers" around the earth. The image of earth we are interested in is round, but the image file is square, and those 4 extra
pieces showed up. I tried making them transparent in gimp, but then the star's baseline color was shown. Even when I tried to make that color transparent in the color file, it didn't work.
One can mitigate this problem decently by using the polysides command, which controls the baseline texture shape. The default is 4, as that would make a square and is easiest to render. 
The maximum allowed is 16, and this would make a regular 16-sided polygon, which is a more convincing circle than a square. Then, the earth texture is drawn onto this polygon, so there are
now 16 much smaller leftovers. When one makes these parts black, its a pretty convincing effect. One should not zoom too closely if there is a bright object near the edge, as this will
clearly highlight a sharp corner or straight. However, from far away, its decent enough. 

As a final problem, eclipse-like effects cannot be easily produced. This is to be expected, since textures are always drawn at the same luminosity, or at least independant of the 
depth-ordering of bright objects. Therefore when the earth passes in front of the sun, we see a fully illuminated face, as opposed to a silhouette. There is not much that can be
done about this, other than manually changing the texture to a black circle at the right time, and then possibly using a crescent, and eventually the original. 


When showing the orbit path of a planet, I had to use a mesh to create a circle. Partiview does have a ellipsoid command, but this produces an ellipsoid.
One can set one of the dimensions to be 0, but it ends up looking like a wheel with spokes since there are still the longitude lines. One can control the number
of longitude lines, but it wouldn't let me not show any of them. I ended up simply generating a mesh of 150 points in a circle and using that. 

One must also add the planet group after the orbit path group in the master .cf file, or else the orbit path will appear "through" the planet (unless this is
desired).

To achieve a color change effect, possibly for blueshift and redshift, one has to change the color datavar in the .cf file,
which corresponds to an index in the cmap file. However, it seems that when the brightness of a points reaches a certain level,
it will be drawn completely as white. In addition, the intensity of a color somehow "adds" with its base texture. I had the problem
that when changing colors, the radius of the star would change. One has to modify the base texture to have a clear star center and
a distinct halo, so that the center is always nearly white, and the halo is free to change color.

To achieve a dimming effect, specifically when it comes to transits, it is best to use the texture mentioned above. Specifically,
One should make 2 versions, a "dark" and a "light" version. The dark version will be the same as the light except the star halo
will be smaller and less bright (but the star center will be identical). The given star color should remain the same. If one tries
to modify the star color, we have the same problem as before, that the star radius will change noticeably. 

I had also given up on a bug related to stars blinking. When viewing "background stars" every time the camera shifted, certain
stars would "blink into existence" and also blink out, almost randomly. Upon reading the manual closer, I found that this is 
an artifact from having a very close near-clippiing plane. I had set it as 1e-5, with the far-plane at 1e5. This is a very large
ratio that apparently gives the engine a problem; this is a known bug. I set the near-plane to 1e-2, which doesn't cost be anything
since I never view points closer than 0.05, and the blinking stopped!

I also encountered a very annoying bug when it came to mapping colors to stars. This was when I was using data pulled from NASA's
exoplanet archive, and I wanted to highlight different subsets of data within partiview. Specifically, I wanted to divide the data
into planets discovered by Kepler, TESS, K2, and others. Initially, I had each partiview group have the same raw data, and then I
specified an "only=" clause to select the appropriate subset. This worked fine for the color mapping, though there were other problems
when it came to doing a time series animation. It seems that having multiple only= clauses messes something up. I know there are only- and
only+ clauses, but those didn't work either. I then decided that the best way to solve this problem was to seperate the subsets to begin with,
and so I would avoid having the only= clause to select the telescope. For example, the Kepler group would have about 2300 data points,
whereas the TESS file would only have 100 or so. However, I found that the color mapping was wrong, nearly all the stars were always blue,
which was color index 2. I spent a very long time trying to figure out what was wrong and I eventually figured out that it was due
to "residue" color indexes. For basic usage, one might declare 4 colors in the .cmap file, and then use those 4 colors (indexes 0-3)
in the .speck file declaring a color datavar. However, by spliting the data, most files didn't use all of the colors. I was coloring
by detection method (radial velocity, transit, etc.), and when I filtered to only have TESS-found stars, there wasn't going to be any
radial velocity stars. However, the color map file still had indexes for radial velocity. In other words, the color map had indicies 0-3
available, but I only used indicies 1 and 2. Theoretically this is totally fine, but partiview syas otherwise. It appears to somehow try to
reindex everything, and it drops a couple of the first color map indicies. This is why everything was blue, because stars that were meant
to be red defaulted to the only available index. Once I figured this out, I fixed this with an appropriately gimmicky solution, I simply
created dummy stars far away from the areas of interest that used all of the color indicies, so every index had at least 1 star using it.
Essentially, make sure there are no extra "declared" colors (and of course no "request" for non-existant colors). 


At this point, looking at some of the orbit lines, I was rather bothered by the aliasing on them. Specifically, one could clearly see
the "staircase" pattern on these lines especially with parts of the curve that were nearly vertical or horizontal. Partiview does not have
an easy option to antialias this, and initially thought I was stuck with it. However, there are several options to consider. Initially, I
researched some antialiasing methods that I could do given an image. Since I was already using opencv and ffmpeg, I tried to find some
tool that they might have. As can be expected, they didn't have much, since it is much easier to mitigate antialiasing in the production
of an image than after it. Then I ran across supersampling, which sounded promising. Partiview is nice in that it allows you to render videos
in any reasonable resolution (takes proportionally more time of course) and so I started with double width and double height. I then scaled
it back to 1080p using ffmpeg. When I looked at the video, it seemed that it barely helped, and that the orbit lines were now gray instead
of white. I eventually realized that partiview's ability to render at any resolution wasn't quite "honest". When it draws its mesh lines,
it **always** draws them as 1 pixel thick, no matter the frame size. Thus when I tried to rener at higher resolution, the line itself stayed
the same resolution. In addition, the final line appeared gray because I now had 1 white pixel per 3840 instead of 1 white pixel per 1920,
so it averaged to "half a white" per 1920, or in other words, gray. 

I then considered trying to do some simple cv to draw over the lines correctly. I could render the video with only the orbit lines (and
with still the correct motion and angles of the camera), and this would effectively tell opencv where the orbits are with no noise. 
Theoretically opencv could then draw over the lines using properly antialiased lines, and then I could somehow take that information and
put it on top of the full video. However, it seemed pretty difficult and I don't have much experience with this part of opencv, so I decided 
not to try.

However, I took another look at the source code. The best solution would be to modify the source code, recompile it, and use my own version
of partiview. If I could get this to work, then potentially I could fix many other problems with partiview, like that fact that the max
sized polygon has only 16 sides. However, as I took a deeper look at the source code, just to look for where I could try to fix antialiasing,
I was once again reminded how hard it would be. Personally I think the code is more convoluted than it needs to be, and there weren't enough
comments to be helpful. I was hoping to find a "drawLine" method, that I could hopefully pass an antialiasing flag, but I never found such
a thing (it might be there though). I did find a generic draw method which seemed to draw everything, and I could set a property of openGL
at the beginning of the method to enable antialiasing.

The biggest problem now was getting the code to compile. I have a windows computer, and because I have not declared a CS major/minor as of
now, I don't have access to undergrad linux computers. Therefore I had to try and compile everything on windows. partiview does have a limited
guide in its manual to compile itself, and I followed that. I had to get Microsoft Visual Studio for the compiliation of FLTK, and I also
installed cygwin to emulate some linux functionality. It was all going fine until the end. From what I can understand, I needed to run
a ./configure script, which would produce "ready to use" header files and the makefile. This wasn't explicitly mentioned in the windows
compilation steps, but it was in the linux one. I tried to compile it without running ./configure, and I just got a bunch of "file not found"
errors. ./configure scripts have to be run on linux, so I used cygwin for that, but there were some syntax problems. I ran a dos2unix conversion
on the configure file, just to make sure it wasn't the /r/n vs /n problem, but that didn't work. I had already spent the better part of a day
working on this, so I have up on this attempt. 

Luckily, while I was hunting through the source code, I came upon the method that parsed the mesh command, which I used to draw my lines. 
To my amazement, there was hidden flag to control line width: -w. This was not in any of the documentation I had ever read, and I only found it
by looking at the code. Apparently, this feature was added in 2009, so they had 12 years to update the documentation. Nevertheless, I tried
out this flag and it worked. This allowed me to go back to supersampling, because now when I try to increase resolution, I can proportionally
scale up the line thickness, so it is a true upscale. I tried it out and it worked quite nicely. I soon found out that lines weren't the only
things that were pixel-bound; stars' halos and points were also drawn by-pixel instead of by-proportion. This meant that I had to 
increase the ptsize and polysize as well, or else the downscaled star would be basically just a smudge of color. I had to play with 
the numbers a bit to find a good compromise, but I ended up with rendering at 4800x2700 (2.5 times 1080p), with line thickness 3,
and also commanding ptsize 0.15 4, and polysize 0.0015. Even with these modifications, it doesn't look exactly like the 1080p video, but
its close enough, and most importantly, the antialiasing is much improved. 
  

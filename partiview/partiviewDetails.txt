To make a star have volume when you get close, you must include its data point twice in the speck file.
Without doing this, when the camera gets close, the point dissappears and only the halo is left over.
In addition, the color map color has to be be sufficiently bright (white) and have a large enough alpha.

To have the halo shape instead of texture, make sure datavar for texture is "linked" to the file to overlay

Finding how partiView handles angles was quite complicated. First, the documentation was very brief about it, and only described it
as Rx Ry Rz. The 0 0 0 config of the camera corresponds to facing parallel to the z axis, facnig the origin, with the x axis
extending out to the right and y axis up. 
Testing simple cases, I found that for single rotations about a coordinate axis, it made sense, but not when I composed rotations.
Initially, I thought the system was to first rotate in the x-y plane and then up toward the z axis, similar to latitute longitude, but 
that didn't work in many cases. 

I went to the source code at https://git.ncsa.illinois.edu/slevy/partiview to see if I could find something there. Although partiView itself is 
lightWeight, the source code is still too dense to just "read through". Certain partiView commands like "jump" take in rotation values, so 
I tried to see how it was converted, but there was little code documentation, and I quickly got to hardcoded matrix formulas with no descriptive
names. The file geometry.c seemed to contain most of the utility methods for these operations. However, I did find a comment nearby that described it as "azimuth, elevation, roll", and also YXZ. All along, I suspected that they were using some standard rotation system like Euler Angles, since all other systems require more information (still 3 degrees of freedom, but "spread out", like axis-angle form). 

I found a rotation converter https://www.andre-gaschler.com/rotationconverter/ that I used to convet axis-angle to Euler Angles. Axis-angle
is probably the easiest input data to create, since ultimately I would like to just specify the camera to look in a certain direction.
I use the cross product between that vector and the default camera (0, 0, -1) to find a mutually orthogonal rotation axis, and the dot product
to find the angle swept. 

I also learned that Euler Angles come in many conventions, and 3D rotation in general has many conventions, such as if we use axes fixed in the
body or the frame, or active and passive rotations, etc. However, this converter I found had convention choices permuting XYZ (as opposed to XZX
which is another common convention), so I chose the YXZ that I saw earlier. To test this, I decided to "request" that the camera look along 
<1, 0.5, -1>, and I calculated the axis-angle rotation by hand. I plugged into the converter and got the YXZ Euler Angles, and put them in 
partiView. Luckily, there is a builtin command called "where", which prints out a lot of useful positional information including the camera's 
"looking vector", and it matched my requested <1, 0.5, -1>, up to a very small numerical error. I tested this a couple more times with other
vectors, and it worked correctly as well. 

I also tested orienting myself in partiView randomly, and looking at the camera's direction vector. I again plugged that into axis-angle and then
the converter, and found the calculated Euler Angles. The first 2 matched exactly with what partiView said, but the 3rd angle was about 15% off.
I have no idea why, and I am fairly sure it was not a calculation mistake on my part. 

Now I was pretty confident that the converter was correct, and so I looked at its source code (which was nicely provided in github). Unfortunately,
it was very long and hard to read, and like partiView, the matrix math was all "baked in" and hard to reproduce. 

At this point, I figured out that I would need to convert axis-angle (or some form produceable from axis-angle) to Euler, but most guides
used the standard XYZ (roll pitch yaw) convention. Essentially the ordering of the axes determines the order of the multiplication of the 
elementary rotation matricies. This was a good guide: http://danceswithcode.net/engineeringnotes/rotations_in_3d/rotations_in_3d_part1.html  though
I refered to many other sources. These sources mainly used the composed rotation matrix form, so that's what I used.

The composed rotation matrix I need is created from Ry(v)Rx(u)Rz(w), which of course matches the YXZ form. These matricies are the standard 3D rotations matricies. I used Mathematica to multiply them. To solve for each angle, one can divide carefully chosen elements of the composed matrix
to isolate sin or cos of u, v, w. Just to make sure all my implicit conventions were correct, I testing this against the converter and it all
worked out.   

Finally, to get the rotation matrix from axis-angle I found a formula on wikipedia https://en.wikipedia.org/wiki/Rotation_matrix#In_three_dimensions and used that. There are no annoying conventions here, so it's a
simple plug in. 

I also investigated an alternative method of creating the rotation matrix, using a regular aziumth-elevation type rotation composition. Axis-angle
works well, but it causes some rolling (as in pitch, yaw, roll), and I wanted to see if I could avoid that. Azimuth-elevation is very much like
spherical polar coordinates, and a horizontal section rotated using this method would remain horizontal. I tried this, and it definately produced
different results, but there were some "fun" barrel rolls for some reason, and it was a little disorienting. I decided to stick with axis-angle. 

*Note this is a summary of my path to get the whole thing to work. There were several more dead ends than I mentioned and I also spent some time 
reminding myself how 3D rotations worked in general.


For the camera angles, I have 2 options, looking directly at the line of travel (similar to a rollar coaster), and fixating on a point. Switching between these options produces a smooth pan.

In order to record a video, partiview will save screenshots after each frame in a path. Specifically, load in a flight path manually, then command 'read makeFrames.cf" this instructs partiview to move to frame 1, save a snapshot,
move to frame 2, save, and so on. One can detach the viewing window using "detach" and also resize it using "winsize x y". This enables partiview to take screenshots at any resolution. Unfortunately it saves it directly into the main
directory, not a new folder, but this isn't a huge deal. I then wrote a small python script using opncv to stitch the frames together at 60 fps. 


In order to animate time-varying data, there are several options. One can specify velocity components for each star in the speck file, as a dataavar, and partiview will do a simple 
linear extrapolation in time. This is only good for linear motion. Another option is using the 'datatime' keyword in the speck file. For every star you want to move, you can provide
xyz coordinates for every step in time. There is no interpolation between these points, and so there has to be quite a few datatimes (several hundereds at least) to see smooth
motion. With this method, any sort of path can be produced (for any number of stars concurrently). There is a final method I found with minimal documentation. One can combine the two
previous methods, with linear interpolation between datatimes. However, unless there are many datatimes, this will produce choppy motion, and the velocities have to be updated
appropriately for each data time to make sure the extrapolation hits the next coordinate point. This is cumbersome and one might as well use the "pure datatimes" method. 


In addition to evolving position with time, one can also evolve other qualities with time, as long as they appear in the .SPECK file. This works best with continuous
variables, such as luminosty. All you need to do is to have it print out a non-constant value through time, and partiview will update the quality accordingly.



The only texture I was able to use was the one in the Digital Universe halo.pbm. I tried opening this file and modifying it using GIMP, but after I saved it, partiview had 
trouble recognizing it. It displayed a large square instead of the texture, which is what it does when there are no textures at all. Looking at the raw data using
a text editor, the data format was clearly different after I saved it using GIMP, so that might be the problem.

To fix this, one should use the .sgi format for images, which partiview also supports. When exporting this format from gimp, one can either select the "RLE compression" or
"No compression option". There are several difficulties however within partiview. For one thing, textures are general shown always facing the camera head on. For star halos, this
makes sense because we would not want to see a "flat" star, and the spherically symmetric enough. For showing detail on a planet however, it becomes impossible to oribt the planet,
as the same thing is always shown! There is a way to specify the actual orientation of a texture using the polyorivar command, which accepts 2 orthonormal vectors that define the 
plane of the texture. This is good to show disc galaxies, for example, but again for a planet it will appear flat when viewed edge-on. 

Another difficulity arises when looking at the texture straight on, and that is that it can appear partially transparent. Again, when showing pictures of galaxies with stars "underneath it",
it makes sense to have it be partially transparent. However, planets are not transparent, and it makes for quite an experience when one can see stars through the planet. Changing the 
alpha value on the texture had some effect, though it never made it fully opaque. I experimented with the planet's point color's opaqueness, but that didn't work. One can stack several points
on top of each other, with identical textures, and while that does improve the opaqueness, it never removes it, and the final image appears over-exposed and blurry.

When declaring textures in the .cf file, there are flags to indicate the mode of drawing textures. For example, the standard star halo uses the -M flag, modulate, which treats the texture
as a brightness channel, and respects the point's original color map color. There is another option, -O, over compost, which will obscure features behind it according to the alpha at each
point on the texture. This does succeed in making the planet opaque, but now there are other problems. 

It seems that when partiview says "obscure other features", they really meant that, regardless of depth. When I made a simple earth-sun system, and the sun was physically between the earth 
and the camera, it was actually entirely blocked by the earth texture. In other words, the texture is always the last thing drawn, regardless of depth. Some of the other command flags for 
adding textures did not have this problem, but of course, they made earth transparent. 

Another problem with the -O option, was that it had black "leftovers" around the earth. The image of earth we are interested in is round, but the image file is square, and those 4 extra
pieces showed up. I tried making them transparent in gimp, but then the star's baseline color was shown. Even when I tried to make that color transparent in the color file, it didn't work.
One can mitigate this problem decently by using the polysides command, which controls the baseline texture shape. The default is 4, as that would make a square and is easiest to render. 
The maximum allowed is 16, and this would make a regular 16-sided polygon, which is a more convincing circle than a square. Then, the earth texture is drawn onto this polygon, so there are
now 16 much smaller leftovers. When one makes these parts black, its a pretty convincing effect. One should not zoom too closely if there is a bright object near the edge, as this will
clearly highlight a sharp corner or straight. However, from far away, its decent enough. 

As a final problem, eclipse-like effects cannot be easily produced. This is to be expected, since textures are always drawn at the same luminosity, or at least independant of the 
depth-ordering of bright objects. Therefore when the earth passes in front of the sun, we see a fully illuminated face, as opposed to a silhouette. There is not much that can be
done about this, other than manually changing the texture to a black circle at the right time, and then possibly using a crescent, and eventually the original. 


When showing the orbit path of a planet, I had to use a mesh to create a circle. Partiview does have a ellipsoid command, but this produces an ellipsoid.
One can set one of the dimensions to be 0, but it ends up looking like a wheel with spokes since there are still the longitude lines. One can control the number
of longitude lines, but it wouldn't let me not show any of them. I ended up simply generating a mesh of 150 points in a circle and using that. 

One must also add the planet group after the orbit path group in the master .cf file, or else the orbit path will appear "through" the planet (unless this is
desired).

To achieve a color change effect, possibly for blueshift and redshift, one has to change the color datavar in the .cf file,
which corresponds to an index in the cmap file. However, it seems that when the brightness of a points reaches a certain level,
it will be drawn completely as white. In addition, the intensity of a color somehow "adds" with its base texture. I had the problem
that when changing colors, the radius of the star would change. One has to modify the base texture to have a clear star center and
a distinct halo, so that the center is always nearly white, and the halo is free to change color.
